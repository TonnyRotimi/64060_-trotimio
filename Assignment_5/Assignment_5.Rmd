---
output:
  html_document: default
  pdf_document: default
---

```{r}
library(factoextra)
library(ISLR)
library(flexclust)
library(cluster)
library(ISLR)
library(caret)
library(class)
library(gmodels)
library(dplyr)
library(clusterCrit)
```

To read the dataset into the software
```{r}
cereal_1 <- read.csv('C:/Users/rotim/Documents/R/Cereals.csv')
```
To remove missing values
```{r}
cereal_1 <-na.omit(cereal_1)
```

3 cereal rows removed after running the code

To select only numeric variables for clustering
```{r}
cereal <- cereal_1[sapply(cereal_1, is.numeric)]
```
To normalize the data
```{r}
cereal <- scale(cereal)
cereal <- as.data.frame(cereal)
```
Apply hierarchical clustering to the data using Euclidean distance to the normalized

```{r}
single_clust <- agnes(cereal, method = "single")
complete_clust <- agnes(cereal, method = "complete")
average_clust <- agnes(cereal, method = "average")
ward_clust <- agnes(cereal, method = "ward")
```
Print the result
```{r}
print(single_clust$ac)
print(complete_clust$ac)
print(average_clust$ac)
print(ward_clust$ac)
```

From the above we see the ward linkage method is the best approach.

We perform heirarchical clustering using the Ward method
```{r}
cereal_names <- cereal_1[, 1]
cereal_dist <- dist(cereal_1[, -1], method = "euclidean")  
ward_cluster <- hclust(cereal_dist, method = "ward.D2")
cutree_ward <- cutree(ward_cluster, k = 6)
cereal_clustered <- cbind(as.data.frame(cereal), Cluster = cutree_ward)
```


How many clusters would you choose?
Now we plot the actual Dendrogram. 
After plotting the dendrogram initially, we see that 6 clusters are appropriate.
```{r}
plot(ward_cluster, cex=0.4, labels = cereal_names)
```

Now we plot the dendrogram with 6 clusters
```{r}
plot(ward_cluster, cex=0.4, labels = cereal_names)
rect.hclust(ward_cluster, k=6, border= 1:4)
```


Using the fviz_nbclust() we also get an idea of the appropriate no of clusters
```{r}
fviz_nbclust(cereal, kmeans, method = "wss")
```
From the graph below we see the elbow point at 6 and that supports our initial decision of 6 clusters.

We Partition the dataset below
```{r}
set.seed(123) 
cereal_2=createDataPartition(cereal_1$calories, p=0.50, list=FALSE)
```

Partition A
```{r}
A_1=cereal_1[cereal_2,]
A <- A_1[sapply(cereal_1, is.numeric)]
A <- scale(A)
```

Partition B
```{r}
B_1=cereal_1[-cereal_2,]
B <- B_1[sapply(cereal_1, is.numeric)]
B <- scale(B)
```



Clustering partition A
```{r}
cereal_dt_A <- dist(A, method = "euclidean")
cluster_A <- hclust(cereal_dt_A, method="ward.D2")
clusters_A <- cutree(cluster_A, k = 6)
```


Use the cluster centroids from A to assign each record in partition B
Now we Calculate cluster centroids

Add a column to A_1 to represent the clusters
```{r}
A_1$cluster <- clusters_A
```

```{r}
cluster_centroids <- aggregate(. ~ cluster, data = A_1[, sapply(A_1, is.numeric)], FUN = mean)

```

Exclude the cluster column from cluster centroids
```{r}
centroids_A <- cluster_centroids[, -1]
```
View Print cluster centroids_A
```{r}
print(centroids_A)
```


Function to assign records in partition B to the closest cluster
```{r}
distances_B_to_centroids <- as.matrix(dist(rbind(centroids_A, B), method = "euclidean"))[nrow(centroids_A) + 1:nrow(B), 1:ncol(centroids_A)]
clusters_B <- apply(distances_B_to_centroids, 1, which.min)
```

Create hierarchical clustering object for partition B
```{r}
cereal_dt_B <- dist(B, method = "euclidean")
cluster_B <- hclust(cereal_dt_B, method = "ward.D2")

```

Plot the Dendrogram for the combined data, Partition A and Partition B then compare

Dendrogram for the Combined data
```{r}
plot(ward_cluster, cex=0.4, labels = cereal_names)
rect.hclust(ward_cluster, k=6, border= 1:4)
```
Identify and print the cereals in the first cluster of the combined cluster
```{r}
cereals_in_cluster_1 <- cereal_names[cutree_ward == 1]

print(cereals_in_cluster_1)
```

Dendrogram for Partition A
```{r}
cereal_names_A <- A_1[, 1]
plot(cluster_A, cex = 0.4, labels = cereal_names_A)
rect.hclust(cluster_A, k = 6, border = 1:4)
```

Identify and print the cereals in the first cluster of cluster_A
```{r}
cluster_indices <- which(clusters_A == 1)
cereals_A <- cereal_names_A[cluster_indices]
print(cereals_A)
```

Dendrogram for Partition B
```{r}
cereal_names_B <- B_1[, 1] # Assuming "Name" is the column containing cereal names in partition B
plot(cluster_B, cex = 0.4, labels = cereal_names_B)  
rect.hclust(cluster_B, k = 6, border = 1:4)
```

Identify and print the cereals in the first cluster of cluster_B
```{r}
cluster_assignments_B <- cutree(cluster_B, k = 6)
cluster_indices <- which(cluster_assignments_B == 1)
cereals_B <- cereal_names_B[cluster_indices]
print(cereals_B)
```

From examining the dendrograms of the partition A and B datasets, we see that cluster 1 for partition A has "[1] "All-Bran_with_Extra_Fiber" as its only cereal, while cluster 1 for partition B has "100% Bran" and "All-Bran" as its cereals, which is consistent with the cereals present in cluster 1 of the of the combined data. Although this is not the case in all clusters,as there is some variation from the clusters made in the partitioned and combined datasets.
  
The elementary public schools would like to choose a set of cereals to include in their...

Compute summary statistics for each cluster
```{r}
cluster_total <- aggregate(cereal_clustered[, -ncol(cereal_clustered)], 
                           by = list(cluster = cutree_ward), FUN = mean)

```

Print the summary statistics for each cluster
```{r}
print(cluster_total)
```

On examination of the clusters, we see that the cereals in cluster 1 are the healthiest
as they have the lowest number of calories, sugar,and weight, while also having the highest amount of fiber, potass and protein. The cereals in cluster 1 also have the higher ratings.

To see and print the names of cereals in cluster 1
```{r}
cereals_in_cluster_1 <- cereal_names[cutree_ward == 1]

print(cereals_in_cluster_1)
```

As a different cereal should be offered everyday, we can also choose cereals from cluster 2 and 4 as they are healthier than the other 3 clusters, as they are rich in protein, fiber and potass.

To see and print the names of cereals in cluster 2 
```{r}
cereals_in_cluster_2 <- cereal_names[cutree_ward == 2]

print(cereals_in_cluster_2)
```

To see and print the names of cereals in cluster 4
```{r}
cereals_in_cluster_4 <- cereal_names[cutree_ward == 4]

print(cereals_in_cluster_4)
```



